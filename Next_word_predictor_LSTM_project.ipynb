{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXyxt3gWnRHcXizGI6hj6T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smartNitish/Deep-Learning/blob/main/Next_word_predictor_LSTM_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text about the course has been taken for example"
      ],
      "metadata": {
        "id": "l45rIIRkvufA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kGvgf7HJeX1f"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"About the Program\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2023)\n",
        "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python Fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "You can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
        "Where can I find the class schedule?\n",
        "Checkout this google sheet to see month by month time table of the course - https://docs.google.com/spreadsheets/d/16OoTax_A6ORAeCg4emgexhqqPv3noQPYKU7RJ6ArOzk/edit?usp=sharing.\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 2 hours.\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish\n",
        "How will I be informed about the upcoming class?\n",
        "You will get a mail from our side before every paid session once you become a paid user.\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely.\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program anytime.\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "Will we do case studies in the program?\n",
        "Yes.\n",
        "Where can we contact you?\n",
        "You can mail us at nitish.campusx@gmail.com\n",
        "Payment/Registration related questions\n",
        "Where do we have to make our payments? Your YouTube channel or website?\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
        "Can we pay the entire amount of Rs 5600 all at once?\n",
        "Unfortunately no, the program follows a monthly subscription model.\n",
        "What is the validity of monthly subscription? Suppose if I pay on 15th Jan, then do I have to pay again on 1st Feb or 15th Feb\n",
        "15th Feb. The validity period is 30 days from the day you make the payment. So essentially you can join anytime you don’t have to wait for a month to end.\n",
        "What if I don’t like the course after making the payment. What is the refund policy?\n",
        "You get a 7 days refund period from the day you have made the payment.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmail.com\n",
        "Post registration queries\n",
        "Till when can I view the paid videos on the website?\n",
        "This one is tricky, so read carefully. You can watch the videos till your subscription is valid. Suppose you have purchased subscription on 21st Jan, you will be able to watch all the past paid sessions in the period of 21st Jan to 20th Feb. But after 21st Feb you will have to purchase the subscription again.\n",
        "But once the course is over and you have paid us Rs 5600(or 7 installments of Rs 799) you will be able to watch the paid sessions till Aug 2024.\n",
        "Why lifetime validity is not provided?\n",
        "Because of the low course fee.\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select past week doubt in the doubt clearance google form.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmai.com\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee of Rs 5600\n",
        "You have to attempt all the course assessments.\n",
        "I am joining late. How can I pay payment of the earlier months?\n",
        "You will get a link to pay fee of earlier months in your dashboard once you pay for the current month.\n",
        "I have read that Placement assistance is a part of this program. What comes under Placement assistance?\n",
        "This is to clarify that Placement assistance does not mean Placement guarantee. So we dont guarantee you any jobs or for that matter even interview calls. So if you are planning to join this course just for placements, I am afraid you will be disappointed. Here is what comes under placement assistance\n",
        "Portfolio Building sessions\n",
        "Soft skill sessions\n",
        "Sessions with industry mentors\n",
        "Discussion on Job hunting strategies\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pVy-bb7wfBZr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "NSTS_Plbv3T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n"
      ],
      "metadata": {
        "id": "Ms7SJiOLeiFk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tokenizer is used for represent unique word with unique number."
      ],
      "metadata": {
        "id": "61p72VURv8C3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n"
      ],
      "metadata": {
        "id": "TGcd5i6ae3_z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "zs1LRLZIfQwq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyVpgrINfXRb",
        "outputId": "1b33953c-5691-41f4-9d9b-db9c7e8d60fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'you': 2,\n",
              " 'i': 3,\n",
              " 'to': 4,\n",
              " 'a': 5,\n",
              " 'of': 6,\n",
              " 'is': 7,\n",
              " 'have': 8,\n",
              " 'will': 9,\n",
              " 'can': 10,\n",
              " 'what': 11,\n",
              " 'course': 12,\n",
              " 'program': 13,\n",
              " 'in': 14,\n",
              " 'for': 15,\n",
              " 'all': 16,\n",
              " 'sessions': 17,\n",
              " 'on': 18,\n",
              " 'be': 19,\n",
              " 'and': 20,\n",
              " 'this': 21,\n",
              " 'if': 22,\n",
              " 'am': 23,\n",
              " 'pay': 24,\n",
              " 'payment': 25,\n",
              " 'make': 26,\n",
              " 'we': 27,\n",
              " 'do': 28,\n",
              " 'subscription': 29,\n",
              " 'where': 30,\n",
              " 'rs': 31,\n",
              " 'so': 32,\n",
              " 'campusx': 33,\n",
              " 'session': 34,\n",
              " 'our': 35,\n",
              " 'paid': 36,\n",
              " 'join': 37,\n",
              " 'able': 38,\n",
              " 'your': 39,\n",
              " 'website': 40,\n",
              " 'placement': 41,\n",
              " 'fee': 42,\n",
              " 'data': 43,\n",
              " 'monthly': 44,\n",
              " 'month': 45,\n",
              " 'not': 46,\n",
              " 'get': 47,\n",
              " 'yes': 48,\n",
              " 'once': 49,\n",
              " 'past': 50,\n",
              " 'feb': 51,\n",
              " 'assistance': 52,\n",
              " 'science': 53,\n",
              " '7': 54,\n",
              " '5600': 55,\n",
              " 'are': 56,\n",
              " 'watch': 57,\n",
              " 'google': 58,\n",
              " 'by': 59,\n",
              " 'com': 60,\n",
              " 'mail': 61,\n",
              " 'from': 62,\n",
              " 'contact': 63,\n",
              " 'us': 64,\n",
              " 'at': 65,\n",
              " 'or': 66,\n",
              " 'doubt': 67,\n",
              " 'mentorship': 68,\n",
              " 'payments': 69,\n",
              " '799': 70,\n",
              " 'total': 71,\n",
              " 'duration': 72,\n",
              " 'months': 73,\n",
              " 'learning': 74,\n",
              " 'case': 75,\n",
              " 'here': 76,\n",
              " 'https': 77,\n",
              " 'part': 78,\n",
              " 'see': 79,\n",
              " 'late': 80,\n",
              " 'dashboard': 81,\n",
              " 'task': 82,\n",
              " 'don’t': 83,\n",
              " 'nitish': 84,\n",
              " 'validity': 85,\n",
              " '15th': 86,\n",
              " 'jan': 87,\n",
              " 'period': 88,\n",
              " 'after': 89,\n",
              " 'till': 90,\n",
              " '21st': 91,\n",
              " 'that': 92,\n",
              " 'about': 93,\n",
              " 'follows': 94,\n",
              " 'model': 95,\n",
              " 'syllabus': 96,\n",
              " 'python': 97,\n",
              " 'ml': 98,\n",
              " 'studies': 99,\n",
              " 'learnwith': 100,\n",
              " 'deep': 101,\n",
              " 'nlp': 102,\n",
              " 'no': 103,\n",
              " 'miss': 104,\n",
              " 'live': 105,\n",
              " 'recording': 106,\n",
              " 'even': 107,\n",
              " 'class': 108,\n",
              " 'time': 109,\n",
              " '2': 110,\n",
              " 'how': 111,\n",
              " 'absolutely': 112,\n",
              " 'middle': 113,\n",
              " 'anytime': 114,\n",
              " 'submit': 115,\n",
              " 'with': 116,\n",
              " 'gmail': 117,\n",
              " 'registration': 118,\n",
              " 'related': 119,\n",
              " 'link': 120,\n",
              " 'entire': 121,\n",
              " 'suppose': 122,\n",
              " 'again': 123,\n",
              " 'days': 124,\n",
              " 'day': 125,\n",
              " 'refund': 126,\n",
              " 'living': 127,\n",
              " 'outside': 128,\n",
              " 'india': 129,\n",
              " 'should': 130,\n",
              " 'sending': 131,\n",
              " 'queries': 132,\n",
              " 'videos': 133,\n",
              " 'read': 134,\n",
              " 'but': 135,\n",
              " 'provided': 136,\n",
              " 'form': 137,\n",
              " '1': 138,\n",
              " 'clearance': 139,\n",
              " 'week': 140,\n",
              " 'just': 141,\n",
              " 'certificate': 142,\n",
              " 'earlier': 143,\n",
              " 'comes': 144,\n",
              " 'under': 145,\n",
              " 'guarantee': 146,\n",
              " 'dsmp': 147,\n",
              " '2023': 148,\n",
              " 'becomes': 149,\n",
              " 'approx': 150,\n",
              " 'covering': 151,\n",
              " 'following': 152,\n",
              " 'modules': 153,\n",
              " 'fundamentals': 154,\n",
              " 'libraries': 155,\n",
              " 'analysis': 156,\n",
              " 'sql': 157,\n",
              " 'maths': 158,\n",
              " 'machine': 159,\n",
              " 'algorithms': 160,\n",
              " 'practical': 161,\n",
              " 'mlops': 162,\n",
              " 'check': 163,\n",
              " 'detailed': 164,\n",
              " 'courses': 165,\n",
              " '637339afe4b0615a1bbed390': 166,\n",
              " 'both': 167,\n",
              " 'program’s': 168,\n",
              " 'curriculum': 169,\n",
              " 'recorded': 170,\n",
              " 'go': 171,\n",
              " 'back': 172,\n",
              " 'find': 173,\n",
              " 'schedule': 174,\n",
              " 'checkout': 175,\n",
              " 'sheet': 176,\n",
              " 'table': 177,\n",
              " 'docs': 178,\n",
              " 'spreadsheets': 179,\n",
              " 'd': 180,\n",
              " '16ootax': 181,\n",
              " 'a6oraecg4emgexhqqpv3noqpyku7rj6arozk': 182,\n",
              " 'edit': 183,\n",
              " 'usp': 184,\n",
              " 'sharing': 185,\n",
              " 'roughly': 186,\n",
              " 'last': 187,\n",
              " 'hours': 188,\n",
              " 'language': 189,\n",
              " 'spoken': 190,\n",
              " 'instructor': 191,\n",
              " 'during': 192,\n",
              " 'hinglish': 193,\n",
              " 'informed': 194,\n",
              " 'upcoming': 195,\n",
              " 'side': 196,\n",
              " 'before': 197,\n",
              " 'every': 198,\n",
              " 'become': 199,\n",
              " 'user': 200,\n",
              " 'non': 201,\n",
              " 'tech': 202,\n",
              " 'background': 203,\n",
              " 'lectures': 204,\n",
              " 'content': 205,\n",
              " 'provide': 206,\n",
              " 'solutions': 207,\n",
              " 'self': 208,\n",
              " 'evaluate': 209,\n",
              " 'yourself': 210,\n",
              " 'questions': 211,\n",
              " 'youtube': 212,\n",
              " 'channel': 213,\n",
              " 'amount': 214,\n",
              " 'unfortunately': 215,\n",
              " 'then': 216,\n",
              " '1st': 217,\n",
              " '30': 218,\n",
              " 'essentially': 219,\n",
              " 'wait': 220,\n",
              " 'end': 221,\n",
              " 'like': 222,\n",
              " 'making': 223,\n",
              " 'policy': 224,\n",
              " 'made': 225,\n",
              " 'post': 226,\n",
              " 'when': 227,\n",
              " 'view': 228,\n",
              " 'one': 229,\n",
              " 'tricky': 230,\n",
              " 'carefully': 231,\n",
              " 'valid': 232,\n",
              " 'purchased': 233,\n",
              " '20th': 234,\n",
              " 'purchase': 235,\n",
              " 'over': 236,\n",
              " 'installments': 237,\n",
              " 'aug': 238,\n",
              " '2024': 239,\n",
              " 'why': 240,\n",
              " 'lifetime': 241,\n",
              " 'because': 242,\n",
              " 'low': 243,\n",
              " 'reach': 244,\n",
              " 'out': 245,\n",
              " 'fill': 246,\n",
              " 'team': 247,\n",
              " 'still': 248,\n",
              " 'ask': 249,\n",
              " 'doubts': 250,\n",
              " 'select': 251,\n",
              " 'gmai': 252,\n",
              " 'criteria': 253,\n",
              " 'there': 254,\n",
              " 'criterias': 255,\n",
              " 'attempt': 256,\n",
              " 'assessments': 257,\n",
              " 'joining': 258,\n",
              " 'current': 259,\n",
              " 'clarify': 260,\n",
              " 'does': 261,\n",
              " 'mean': 262,\n",
              " 'dont': 263,\n",
              " 'any': 264,\n",
              " 'jobs': 265,\n",
              " 'matter': 266,\n",
              " 'interview': 267,\n",
              " 'calls': 268,\n",
              " 'planning': 269,\n",
              " 'placements': 270,\n",
              " 'afraid': 271,\n",
              " 'disappointed': 272,\n",
              " 'portfolio': 273,\n",
              " 'building': 274,\n",
              " 'soft': 275,\n",
              " 'skill': 276,\n",
              " 'industry': 277,\n",
              " 'mentors': 278,\n",
              " 'discussion': 279,\n",
              " 'job': 280,\n",
              " 'hunting': 281,\n",
              " 'strategies': 282}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each sentence has been written in number form or word has been replaced with number. And then it is convet to input formet for the model."
      ],
      "metadata": {
        "id": "WKNeGtFuwWfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence =[]\n",
        "for sentence in faqs.split('\\n'):\n",
        "  # print(sentence)\n",
        "  # print(tokenizer.texts_to_sequences([sentence])[0])\n",
        "  tokenize_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenize_sentence)):\n",
        "    n_gram=tokenize_sentence[:i+1]\n",
        "    input_sequence.append(n_gram)\n",
        "  # print(input_sequence)\n"
      ],
      "metadata": {
        "id": "DdQ1xSNsffDG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_sequence"
      ],
      "metadata": {
        "id": "ITJyX-0Rf10R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Qui5ea1jMNf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "find the max length of word in a sentence in whole data."
      ],
      "metadata": {
        "id": "Yp-LSg5Rw1E9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=max([len(x) for x in input_sequence])"
      ],
      "metadata": {
        "id": "t2j0jTCOhT7l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PeUpbjsxjAHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding has been imported, for making all input sentence of same size."
      ],
      "metadata": {
        "id": "SWt-K84SxBte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences=pad_sequences(input_sequence,maxlen=max_len,padding='pre')"
      ],
      "metadata": {
        "id": "W0zLnv3cjWCF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhL27AWwjwbI",
        "outputId": "d280a711-e5b5-4978-b40e-a371f8612841"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  93,   1],\n",
              "       [  0,   0,   0, ...,  93,   1,  13],\n",
              "       [  0,   0,   0, ...,   0,  11,   7],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 279,  18, 280],\n",
              "       [  0,   0,   0, ...,  18, 280, 281],\n",
              "       [  0,   0,   0, ..., 280, 281, 282]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = padded_input_sequences[:,:-1]\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12dmOK8dkBrx",
        "outputId": "57d9a95f-ad36-45f3-b693-6eb3875cacf0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0 ...   0   0  93]\n",
            " [  0   0   0 ...   0  93   1]\n",
            " [  0   0   0 ...   0   0  11]\n",
            " ...\n",
            " [  0   0   0 ...   0 279  18]\n",
            " [  0   0   0 ... 279  18 280]\n",
            " [  0   0   0 ...  18 280 281]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output data"
      ],
      "metadata": {
        "id": "ecRiZZrcxQLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_sequences[:,-1]\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MCLlTCikL0c",
        "outputId": "baa6d72b-32c9-4210-9e98-486f70dc590c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1  13   7   1  12  42  15  43  53  68  13 147 148  12  94   5  44  29\n",
            "  95  30   2   8   4  26  44  69   6  31  70  45   7   1  71  72   6   1\n",
            "  12  71  72   6   1  12   7  54  73  32   1  71  12  42 149  70  54  31\n",
            "  55 150   7   1  96   6   1  68  13   9  19 151   1 152 153 154 155  15\n",
            "  43  53 156  15  43  53  15 159  74 160  98  99  10 163   1 164  96  76\n",
            "  77 100  33  14 165  33  43  53  68  13 166 101  74  20 102  19   5  78\n",
            "   6  21  13 102  20 101  74 167  56  46   5  78   6  21 168 169  22   3\n",
            " 104   5 105  34   9   3  47   5 106   6   1  34  16  35  17  56 170  32\n",
            " 107  22   2 104   5  34   2  10 171 172  20  57   1 106  10   3 173   1\n",
            " 108 174  21  58 176   4  79  45  59  45 109 177   6   1  12  77 178  58\n",
            "  60 179 180 181 182 183 184 185   7   1 109  72   6  16   1 105  17  16\n",
            "   1  17 187 110 188   7   1 189 190  59   1 191 192   1  17   9   3  19\n",
            " 194  93   1 195 108   9  47   5  61  62  35 196 197 198  36  34  49   2\n",
            " 199   5  36 200   3  28  21  12  22   3  23  62   5 201 202 203 112  23\n",
            "  80  10   3  37   1  13  14   1 113   2  10  37   1  13 114   3  37  24\n",
            "  14   1 113   9   3  19  38   4  79  16   1  50 204  49   2  26   1  25\n",
            "   2   9  19  38   4  79  16   1  50 205  14  39  81  28   3   8   4 115\n",
            "   1  82  83   8   4 115   1  82  27   9 206   2 116   1 207   2   8   4\n",
            " 208 209   1  82 210  27  28  75  99  14   1  13  10  27  63   2  10  61\n",
            "  64  65  84  33 117  60 118 119 211  28  27   8   4  26  35  69  39 212\n",
            " 213  66  40   8   4  26  16  39  44  69  18  35  40  76   7   1 120  15\n",
            "  35  40  77 100  33  14  27  24   1 121 214   6  31  55  16  65  49 103\n",
            "   1  13  94   5  44  29  95   7   1  85   6  44  29 122  22   3  24  18\n",
            "  86  87 216  28   3   8   4  24 123  18 217  51  66  86  51  51   1  85\n",
            "  88   7 218 124  62   1 125   2  26   1  25  32 219   2  10  37 114   2\n",
            "  83   8   4 220  15   5  45   4 221  22   3  83 222   1  12  89 223   1\n",
            "  25  11   7   1 126 224  47   5  54 124 126  88  62   1 125   2   8 225\n",
            "   1  25  23 127 128 129  20   3  23  46  38   4  26   1  25  18   1  40\n",
            "  11 130   3  28   8   4  63  64  59 131   5  61  65  84  33 117  60 118\n",
            " 132 227  10   3 228   1  36 133  18   1  40 229   7 230  32 134 231   2\n",
            "  10  57   1 133  90  39  29   7 232 122   2   8 233  29  18  91  87   2\n",
            "   9  19  38   4  57  16   1  50  36  17  14   1  88   6  91  87   4 234\n",
            "  51 135  89  91  51   2   9   8   4 235   1  29 123  49   1  12   7 236\n",
            "  20   2   8  36  64  31  55  66  54 237   6  31  70   2   9  19  38   4\n",
            "  57   1  36  17  90 238 239 241  85   7  46 136   6   1 243  12  42  10\n",
            "   3 244 245  14  75   6   5  67  89   1  34   9   8   4 246   5  58 137\n",
            " 136  14  39  81  20  35 247   9  63   2  15   5 138  18 138  67 139  34\n",
            "   3  37   1  13  80  10   3 248 249  50 140 250 141 251  50 140  67  14\n",
            "   1  67 139  58 137  23 127 128 129  20   3  23  46  38   4  26   1  25\n",
            "  18   1  40  11 130   3  28   8   4  63  64  59 131   5  61  65  84  33\n",
            " 252  60  20  41  52 119 132   7   1 253   4  47   1 142  56 110 255   8\n",
            "   4  24   1 121  42   6  31  55   8   4 256  16   1  12 257  23 258  80\n",
            " 111  10   3  24  25   6   1 143  73   9  47   5 120   4  24  42   6 143\n",
            "  73  14  39  81  49   2  24  15   1 259  45   8 134  92  41  52   7   5\n",
            "  78   6  21  13  11 144 145  41  52   7   4 260  92  41  52 261  46 262\n",
            "  41 146  32  27 263 146   2 264 265  66  15  92 266 107 267 268  32  22\n",
            "   2  56 269   4  37  21  12 141  15 270   3  23 271   2   9  19 272  76\n",
            "   7  11 144 145  41  52 274  17 276  17 116 277 278  18 280 281 282]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ1xHH3skawK",
        "outputId": "5e27ea95-7c54-47b1-f6f7-733c1a74fdf0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(863, 56)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8rXnKdel6gA",
        "outputId": "9438e179-ac12-4883-bc38-4fe7bd7a1225"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(863,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output data has been hot encoded"
      ],
      "metadata": {
        "id": "kyCmM6EYxT9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y=to_categorical(y, num_classes=283)"
      ],
      "metadata": {
        "id": "6Ut5Kmvhl7ab"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJUOw58jmObW",
        "outputId": "7e2a32ca-358d-4391-8a6f-a77c06dabfd9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(863, 283)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model architecture has been made for LSTM."
      ],
      "metadata": {
        "id": "JUdd_0RuxbcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense"
      ],
      "metadata": {
        "id": "BwxZ1OYtm5HF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(283,100,input_length=56))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(283,activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m7zoBaToGn3",
        "outputId": "f8703700-14aa-4392-ee39-5fb715759a20"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VReOCWh8oe-_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "UK0Z7KusouQY",
        "outputId": "8b5e7556-6366-4737-fe0b-3f027fb13b1c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-aMYJwyozc7",
        "outputId": "95cbf3cf-03dc-44eb-b689-10df3f5d3b74"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.0506 - loss: 5.5593\n",
            "Epoch 2/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.0792 - loss: 5.0674\n",
            "Epoch 3/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.0717 - loss: 5.0071\n",
            "Epoch 4/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.0863 - loss: 4.9439\n",
            "Epoch 5/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.0708 - loss: 4.9349\n",
            "Epoch 6/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.0918 - loss: 4.7981\n",
            "Epoch 7/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.1187 - loss: 4.5874\n",
            "Epoch 8/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.1261 - loss: 4.4698\n",
            "Epoch 9/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.1755 - loss: 4.1918\n",
            "Epoch 10/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.1988 - loss: 3.9265\n",
            "Epoch 11/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.2250 - loss: 3.7875\n",
            "Epoch 12/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.2678 - loss: 3.5190\n",
            "Epoch 13/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 0.2929 - loss: 3.3697\n",
            "Epoch 14/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.3247 - loss: 3.1341\n",
            "Epoch 15/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.3681 - loss: 2.9191\n",
            "Epoch 16/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - accuracy: 0.3725 - loss: 2.8399\n",
            "Epoch 17/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.4033 - loss: 2.7096\n",
            "Epoch 18/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.4408 - loss: 2.5000\n",
            "Epoch 19/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - accuracy: 0.4963 - loss: 2.3210\n",
            "Epoch 20/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.5241 - loss: 2.2265\n",
            "Epoch 21/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.5706 - loss: 2.1159\n",
            "Epoch 22/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - accuracy: 0.6226 - loss: 1.9539\n",
            "Epoch 23/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.6094 - loss: 1.8160\n",
            "Epoch 24/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.6807 - loss: 1.6429\n",
            "Epoch 25/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 124ms/step - accuracy: 0.6674 - loss: 1.6118\n",
            "Epoch 26/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.7084 - loss: 1.4851\n",
            "Epoch 27/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 0.7422 - loss: 1.3990\n",
            "Epoch 28/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.7747 - loss: 1.2945\n",
            "Epoch 29/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.7914 - loss: 1.2343\n",
            "Epoch 30/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.8060 - loss: 1.1134\n",
            "Epoch 31/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.8086 - loss: 1.0740\n",
            "Epoch 32/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.8383 - loss: 0.9937\n",
            "Epoch 33/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.8492 - loss: 0.9750\n",
            "Epoch 34/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - accuracy: 0.8471 - loss: 0.9070\n",
            "Epoch 35/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.8799 - loss: 0.8234\n",
            "Epoch 36/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.8783 - loss: 0.7756\n",
            "Epoch 37/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - accuracy: 0.8796 - loss: 0.7355\n",
            "Epoch 38/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.8867 - loss: 0.7143\n",
            "Epoch 39/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.9042 - loss: 0.6485\n",
            "Epoch 40/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.9073 - loss: 0.6502\n",
            "Epoch 41/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.9092 - loss: 0.5839\n",
            "Epoch 42/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.9190 - loss: 0.5833\n",
            "Epoch 43/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.9301 - loss: 0.5304\n",
            "Epoch 44/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.9306 - loss: 0.4786\n",
            "Epoch 45/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.9240 - loss: 0.5052\n",
            "Epoch 46/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - accuracy: 0.9368 - loss: 0.4577\n",
            "Epoch 47/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.9423 - loss: 0.4436\n",
            "Epoch 48/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.9363 - loss: 0.4246\n",
            "Epoch 49/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.9395 - loss: 0.4018\n",
            "Epoch 50/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 123ms/step - accuracy: 0.9440 - loss: 0.3927\n",
            "Epoch 51/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9408 - loss: 0.3583\n",
            "Epoch 52/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.9421 - loss: 0.3344\n",
            "Epoch 53/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - accuracy: 0.9403 - loss: 0.3308\n",
            "Epoch 54/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9439 - loss: 0.3223\n",
            "Epoch 55/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 0.9333 - loss: 0.3284\n",
            "Epoch 56/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9562 - loss: 0.2763\n",
            "Epoch 57/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.9574 - loss: 0.2780\n",
            "Epoch 58/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 121ms/step - accuracy: 0.9449 - loss: 0.2671\n",
            "Epoch 59/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.9395 - loss: 0.2861\n",
            "Epoch 60/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.9439 - loss: 0.2609\n",
            "Epoch 61/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.9546 - loss: 0.2523\n",
            "Epoch 62/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.9629 - loss: 0.2229\n",
            "Epoch 63/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.9632 - loss: 0.2260\n",
            "Epoch 64/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.9421 - loss: 0.2552\n",
            "Epoch 65/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - accuracy: 0.9478 - loss: 0.2330\n",
            "Epoch 66/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9519 - loss: 0.2200\n",
            "Epoch 67/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.9424 - loss: 0.2237\n",
            "Epoch 68/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.9531 - loss: 0.2095\n",
            "Epoch 69/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - accuracy: 0.9531 - loss: 0.2036\n",
            "Epoch 70/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.9518 - loss: 0.1995\n",
            "Epoch 71/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.9437 - loss: 0.2126\n",
            "Epoch 72/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - accuracy: 0.9552 - loss: 0.1720\n",
            "Epoch 73/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.9501 - loss: 0.1884\n",
            "Epoch 74/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.9565 - loss: 0.1757\n",
            "Epoch 75/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.9398 - loss: 0.2047\n",
            "Epoch 76/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.9437 - loss: 0.1811\n",
            "Epoch 77/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.9515 - loss: 0.1748\n",
            "Epoch 78/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9503 - loss: 0.1776\n",
            "Epoch 79/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.9541 - loss: 0.1673\n",
            "Epoch 80/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 119ms/step - accuracy: 0.9341 - loss: 0.1809\n",
            "Epoch 81/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.9450 - loss: 0.1709\n",
            "Epoch 82/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.9456 - loss: 0.1740\n",
            "Epoch 83/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - accuracy: 0.9455 - loss: 0.1710\n",
            "Epoch 84/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.9472 - loss: 0.1724\n",
            "Epoch 85/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.9460 - loss: 0.1660\n",
            "Epoch 86/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - accuracy: 0.9427 - loss: 0.1588\n",
            "Epoch 87/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.9549 - loss: 0.1286\n",
            "Epoch 88/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.9530 - loss: 0.1443\n",
            "Epoch 89/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 0.9433 - loss: 0.1438\n",
            "Epoch 90/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.9535 - loss: 0.1365\n",
            "Epoch 91/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.9512 - loss: 0.1449\n",
            "Epoch 92/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.9567 - loss: 0.1425\n",
            "Epoch 93/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9455 - loss: 0.1462\n",
            "Epoch 94/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.9581 - loss: 0.1351\n",
            "Epoch 95/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.9478 - loss: 0.1332\n",
            "Epoch 96/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - accuracy: 0.9507 - loss: 0.1441\n",
            "Epoch 97/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9545 - loss: 0.1251\n",
            "Epoch 98/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.9476 - loss: 0.1302\n",
            "Epoch 99/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - accuracy: 0.9469 - loss: 0.1252\n",
            "Epoch 100/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9556 - loss: 0.1263\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c4c471042e0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text ='mail'\n",
        "# tokenize\n",
        "tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "#padding\n",
        "padded_token_text=pad_sequences([tokenizer.texts_to_sequences([text])[0]],maxlen=56,padding='pre')\n",
        "# print(padded_token_text)\n",
        "#prediction\n",
        "model.predict(padded_token_text).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhy4zKUoqWow",
        "outputId": "c4168694-8e25-4687-9280-1f6f8c47e74a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 283)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "JQ0o9OPlr08J"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos=np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "for word,index in tokenizer.word_index.items():\n",
        "  if index==pos:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dld9l-ZisWq7",
        "outputId": "c31dfd31-bf56-4216-a753-d671c9ded189"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "just\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# text ='mail'\n",
        "# text = 'nlp and deep learning'\n",
        "# text ='total duration of this course'\n",
        "text='what is fee of this course'\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  padded_token_text= pad_sequences([token_text],maxlen=56,padding='pre')\n",
        "  pos=np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index==pos:\n",
        "      text=text+' '+word\n",
        "      print(text)\n",
        "      time.sleep(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh6fMv92seWe",
        "outputId": "7bf5cc45-4aa9-4290-dcbe-86b05bd609ed"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "what is fee of this course is\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "what is fee of this course is the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "what is fee of this course is the day\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "what is fee of this course is the day you\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "what is fee of this course is the day you have\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "what is fee of this course is the day you have made\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "what is fee of this course is the day you have made the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "what is fee of this course is the day you have made the payment\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "what is fee of this course is the day you have made the payment so\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "what is fee of this course is the day you have made the payment so essentially\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TVC5zN__uDnA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}